# Lets do some math!

## Simple statistical model
OK. There is no such thing as simple statistical model. However there are lots of packages that will make you suffer less. In fact this is one of biggest **R** advantages, that you can make even very sophisticated statistical modelling without any knowledge on programming since you use *black boxes*. When you are dealing with classic statistical models many of them are included in **base R** distribution - like linear or generalized additive models. You would probably need to use mixed effect models, at some point. Good news is that there is a very nice and quite straightforward to use library called `lme4` . Every time you run into problem, and you do not know what to use for statistical modelling, or how to perform full procedure, just query Google. There are hundreds of blogs, web pages and *Stack Overflow* discussion on it.

## Other models

### Libraries
Other, usually dynamic models require more knowledge, experience and some libraries. Before you start looking for more tailored solutions, install following libraries: `deSolve`, `fitdistrplus`, `rriskDistributions` and `truncdist`. First one contains tools for solving differential equations sets, second and third provides you tools to deal with distributions (such as comparing distributions or estimating its parameters), and the last one allows you to use truncated distributions.

### Simple mechanistic model and noise
To show some basic mechanistic model, we will use the well known Michaelis-Menten function: $f(x) = \frac{ax}{b+x}$, with *parameter a = 2.15* and *parameter b = 0.08*.
```{r fig.height = 4}
parA <- 2.15
parB <- 0.08
varX <- rbeta(1000, 3, 50)
mmFunction <- parA * varX/(parB + varX)
par(mfrow = c(1,2))
plot(mmFunction~varX, type = 'lines')
#since R have its mysterious ways to deali with plots, when you see somthing like first plot
#try to order your explanatory variable like in code below 
varX <- sort(rbeta(1000, 3, 50))
mmFunction <- parA * varX/(parB + varX)
plot(mmFunction~varX, type = 'lines')
par(mfrow = c(1,1))
```
As you can see, as long as you have simple equation it is very strightforward to translate it into R. But we want something more usefull, for instance adding noise or uncertainty to our model. Lets asume, that we are not sure what is the value of *parameter a*. Lets say that from previous research and expert knowledge we assume that it can be as high 2.5, but never is lower than 1.8. Also it usually takes value of 2.15. Knowing this we can use PERT distribution to include uncertainty in model.

```{r fig.height = 4}
library('mc2d')
sParA <- rpert(1000, 1.8, 2.15, 2.5)
parB <- 0.08
mmSAFunction <- sParA * varX/(parB + varX)
plot(mmSAFunction~varX, type = 'lines')
```
We added some uncertainty to our function. But what with *parameter b*, how our uncertainty on its value affects the outcome? Lets assume that it's value is normally distributed whith *mean = 0.8* and *sd = 0.23*

```{r fig.height = 4}
sParB <- rnorm(1000, 0.08, 0.023) 
mmSABFunction <- sParA * varX/(sParB + varX)
plot(mmSABFunction~varX, type = 'lines')

```
It seems that inclusion of uncertainty on value of *parameter b* does not change our outcomp in any visible manner. So lets include some variability into the outcome. We can assume that for some reasons value of function will vary for different reasons than our uncertainty about value of both *parameters*. And usually it varies from $f(x)$ by some value from uniform distribution. The 25^th and 75^th percentile are given by: `-0.13` and `0.17`. To calculate parameters of this distribution we will use `rriskDistributions` package
```{r}
library('rriskDistributions')
unifParams <- get.unif.par(p = c(0.25, 0.75), q = c(-0.13, 0.17), plot = F)
summary(unifParams)
fVariability <- runif(1000, min = unifParams[1], max = unifParams[2])
mmFSFunction <- ((sParA * varX/(sParB + varX)) + fVariability)
plot(mmFSFunction~varX, type = 'lines')

fVariability[c(1:20)]
mmSAFunction[c(1:10)]
mmSABFunction[c(1:10)]
mmFSFunction[c(1:10)]

```
It seems that there are vey minor differences between those three plots. So lets overlay them one on another to inspect visually differences.
```{r fig.height = 5}
plot(varX, mmFunction, type = 'lines', col = 'black', ylim = c(0, 2))
lines(varX, mmSAFunction, col = 'blue')
lines(varX, mmSABFunction, col = 'green', lty = 'dashed')
lines(varX, mmFSFunction, col = 'red', lty = 'dotted')
```
### Mechanistic model in **R**


### Solving differential equations

